{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqx_f4_WzWg",
        "colab_type": "text"
      },
      "source": [
        "# SSL using Improved Unsupervised Discriminant Projection(UDA)\n",
        "* Unsupervised Discriminant Projection(UDA) is a **dimension reduction** algorithm.\n",
        "* This paper uses UDA as *regularization* which utilize both **local** and **non-local** data distribution for semi-supervised learning.\n",
        "* Original version: applicable for small scale dataset only.\n",
        "\n",
        "## Basic idea of UDP\n",
        "* Direction of projection, w based on the ratio of local scatter to non-local scatter. Therefore, the optimal projection:\n",
        "\n",
        "$$\n",
        "w^* = arg\\:min J(w) = \\frac{J_L}{J_N}\\\\J_L=Local\\:scatter,J_N=Non-local\\:scatter\n",
        "$$\n",
        "* Means we want:\n",
        "$$\n",
        "J_L\\downarrow J_N\\uparrow\n",
        "$$\n",
        "\n",
        ">Close data closer, distant data more distant.\n",
        "\n",
        "## Mathematical representation\n",
        "### Some notations before diving deeper\n",
        "* The weighted adjacency matrix(RBF kernel),Kij indicates closer data larger value:  \n",
        "\n",
        "$$\n",
        "K_{ij} = \\begin{cases}exp(-||x_i-x_j||^2/t) & {if\\:x_j\\:is\\:among\\:K\\:nearest\\:neighbors\\:of\\:x_i\\\\ or\\:x_i\\:is\\:among\\:K\\:nearest\\:neighbors\\:of\\:x_j}\\\\0 & othervise\\end{cases}\n",
        "$$\n",
        "\n",
        "* Hij:  \n",
        "\n",
        "$$\n",
        "H_{ij} = \\begin{cases}K_{ij}& {if\\:x_j\\:is\\:among\\:K\\:nearest\\:neighbors\\:of\\:x_i\\\\ or\\:x_i\\:is\\:among\\:K\\:nearest\\:neighbors\\:of\\:x_j}\\\\0 & othervise\\end{cases}\n",
        "$$  \n",
        "\n",
        "### Original version\n",
        "Note: y_i and y_j are projected samples\n",
        "Local scatter:\n",
        "$$\n",
        "J_L(w) = \\frac{1}{MM} \\sum_{i=1}^M \\sum_{j=1}^M K_{ij}(y_i-y_j)^2\n",
        "$$\n",
        "> Multiplying K_ij involves distance measures of neighbouring samples only\n",
        "\n",
        "Non-local scatter:\n",
        "$$\n",
        "J_N(w) = \\frac{1}{MM} \\sum_{i=1}^M \\sum_{j=1}^M (K_{ij}-H_{ij})(y_i-y_j)^2\n",
        "$$\n",
        "> Multiplying (K_ij-H_ij) involves distance measures of distant samples only\n",
        "\n",
        "### Improved version\n",
        "The local scatter is same as original version. Non-local scatter is defined as below:\n",
        "$$\n",
        "J_D=\\frac{1}{m} \\sum_{i=1,j\\in D^N}^M W_{ij}||y_i-y_j||_2^2\n",
        "$$\n",
        "where Wij is defined as below:\n",
        "$$\n",
        "W_{ij} = \\begin{cases}exp(-||x_i-x_j||^2/t) & {if\\:x_j\\:is\\:among\\:N\\:furthest\\:samples\\:from\\:x_i\\\\ or\\:x_i\\:is\\:among\\:N\\:furthest\\:samples\\:from\\:x_j}\\\\0 & othervise\\end{cases}\n",
        "$$\n",
        "\n",
        "The objective function of the improved UDP:\n",
        "$$\n",
        "J_R(W)=\\frac{J_L}{J_D}=\\sum_{i=1}^M \\frac{\\sum_{j\\in U^K} H_{ij}||y_i-y_j||_2^2}{\\sum_{b\\in D^N} W_{ij}||y_i-y_b||_2^2}\n",
        "$$\n",
        "## Using UDP in semi-supervised learning\n",
        "The objective function:\n",
        "$$\n",
        "J = \\sum_{i=1}^L l(f_i,y_i)+ \\lambda \\sum_{i=1,\\:j\\in U^K,\\:k\\in D^N}^{L+U} J_R(g_i,g_j,g_k,H_{ij},W_{ik})\n",
        "$$\n",
        "> l(.)-----labeled loss \\\n",
        "> JR-----UDP regularization term\\\n",
        "> gi,gj,gk------embeddings of the samples through deep network\\\n",
        ">Uk=local set, DN=distant data set\n",
        "\n",
        "## Conclusion\n",
        "* Similarity between two samples are measured using **Euclidean distance**.\n",
        "* **Weighted adjacency matrix** is used to measure the degree of \"nearest\" of K neighbors, instead of labeling all K neigbors as identical neighbours.\n",
        "* Scatter function is related to Laplacian(refer Laplacian note).\n",
        "\n",
        "## Reference\n",
        "* [Improved UDP Paper](https://arxiv.org/pdf/1912.09147.pdf \"arxiv.org\")\n",
        "\n",
        "## Doubts\n",
        "* Unlabeled data->feed into deep network->gi,gj,gk->UDP?\n",
        "* What is the difference between improved distant scatter function and original distant scatter function?\n",
        "\n",
        "## Author\n",
        "Author: Lee Zhicheng  \n",
        "Date: 02/05/2020\n"
      ]
    }
  ]
}